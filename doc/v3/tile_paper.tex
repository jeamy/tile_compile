\documentclass[10pt,a4paper]{article}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{subcaption}
\usepackage{enumerate}

\title{Tile-Based Quality Reconstruction for Deep Sky Objects: \\A Spatio-Temporal Adaptive Stacking Methodology}

\author{
  Astronomical Imaging Research Group\\
  \texttt{contact@astronomical-imaging.org}
}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
We present a novel method for reconstructing high-quality deep sky object (DSO) images from sequences of short-exposure frames. Unlike traditional stacking approaches that apply global frame selection or weighting, our method explicitly models two orthogonal quality dimensions: global atmospheric conditions and local seeing-driven quality. The tile-based reconstruction algorithm creates a spatio-temporal quality map that allows each region of each frame to contribute according to its information content. We demonstrate that this approach yields superior resolution and signal-to-noise characteristics compared to traditional methods, with FWHM improvements of 5-10\% and enhanced field homogeneity. The algorithm operates on linear data without frame rejection, ensuring that all captured photons contribute to the final result. We describe two equivalent implementation paths: a Siril-based approach using established registration and debayer logic, and a methodically cleaner CFA-based approach. Extensive validation procedures ensure the quality and reliability of the reconstruction. This methodology is particularly effective for large datasets (800+ frames) but includes a graceful degradation path for smaller collections.
\end{abstract}

\section{Introduction}
Deep sky astronomical imaging typically relies on stacking multiple short-exposure frames to improve signal-to-noise ratio. Traditional stacking methods often apply global frame selection or weighting based on overall frame quality. However, astronomical seeing and other quality factors can vary both spatially across the field and temporally during an imaging session.

Our tile-based quality reconstruction method addresses these limitations by using a local quality assessment approach. Rather than evaluating frames globally, we divide them into overlapping tiles and independently assess the quality of each tile in each frame. This creates a spatio-temporal quality map that allows information from each frame to contribute precisely where it provides the highest quality.

The method replaces the traditional search for "best frames" with a comprehensive quality map that utilizes each piece of information exactly where it is physically valid. It operates on linear data without frame rejection, ensuring that all captured photons contribute to the final result.

\section{Methodology}

\subsection{Objective and Assumptions}
The goal of our method is to reconstruct a spatially and temporally optimally weighted signal from fully registered, linear short-exposure frames of astronomical deep sky objects.

\subsubsection{Hard Assumptions}
Our method requires:
\begin{itemize}
\item Linear data (no stretch, no non-linear operators)
\item No frame selection (pixel-level artifact rejection is allowed)
\item Channel-separated processing (no channel coupling)
\item Strictly linear pipeline (no feedback loops)
\item Uniform exposure time across frames (tolerance: ±5\%)
\end{itemize}

\subsubsection{Soft Assumptions}
The method works optimally with:
\begin{itemize}
\item Frame count $\geq 800$ (minimum 50, reduced mode for 50-199 frames)
\item Registration residual $< 0.3$ px (warning if $> 0.5$ px, maximum 1.0 px)
\item Star elongation $< 0.2$ (warning if $> 0.3$, maximum 0.4)
\end{itemize}

\subsection{Preprocessing Paths}
We define two equivalent but different paths for preprocessing:

\subsubsection{Siril-based path (A)}
This path leverages Siril's proven registration and debayer capabilities:
\begin{enumerate}
\item Debayer raw OSC frames using Siril (interpolation)
\item Register frames using Siril (star detection, transform estimation, rotation/translation)
\item Split the registered, debayered RGB frames into separate R, G, and B channels
\end{enumerate}

\subsubsection{CFA-based path (B)}
This methodically cleaner approach avoids color-dependent interpolation before tile analysis:
\begin{enumerate}
\item Derive CFA luminance from real samples (G-dominant or sum)
\item Estimate one transform per frame using robust methods (RANSAC/ECC)
\item Split CFA mosaic into 4 subplanes (R, G1, G2, B)
\item Apply the identical transform to each subplane without interpolation across Bayer phases
\item Re-interleave to CFA
\item Split into R, G, and B channels
\end{enumerate}

From this point onward, both paths follow the same procedure.

\subsection{Global Normalization}
The first critical step is global linear normalization to decouple photometric transparency fluctuations from quality metrics. For each frame $f$ and color channel $c$:

\begin{align}
B_{f,c} &= \text{median}(I_{f,c}) \\
I'_{f,c} &= \frac{I_{f,c}}{B_{f,c}} \\
\sigma_{f,c} &= \text{std}(I'_{f,c}) \\
E_{f,c} &= \text{gradient\_energy}(I'_{f,c})
\end{align}

The normalization must be performed exactly once, before any metric computation, and separately for each color channel.

\subsection{Global Frame Metrics}
For each normalized frame $f$, we compute:
\begin{itemize}
\item $B_f$ – global background level (robust, masked)
\item $\sigma_f$ – global noise
\item $E_f$ – gradient energy (large-scale structure)
\end{itemize}

All metrics are robustly scaled using median and median absolute deviation (MAD):
\begin{equation}
\tilde{x} = \frac{x - \text{median}(x)}{1.4826 \cdot \text{MAD}(x)}
\end{equation}

The global quality score is:
\begin{equation}
Q_f = \alpha(-\tilde{B}_f) + \beta(-\tilde{\sigma}_f) + \gamma\tilde{E}_f
\end{equation}

Where $\alpha + \beta + \gamma = 1$, with default values $\alpha = 0.4$, $\beta = 0.3$, $\gamma = 0.3$. $Q_f$ is clamped to $[-3, +3]$ before computing the global weight:
\begin{equation}
G_f = \exp(Q_f)
\end{equation}

\subsection{Tile Geometry}
To capture local quality variations, the image is divided into overlapping tiles. The tile size adapts to the seeing conditions:

\begin{align}
T_0 &= s \cdot F \\
T &= \lfloor\text{clip}(T_0, T_{\text{min}}, \lfloor\min(W, H) / D\rfloor)\rfloor \\
O &= \lfloor o \cdot T \rfloor \\
S &= T - O
\end{align}

Where:
\begin{itemize}
\item $F$ is the robust FWHM estimate in pixels
\item $s$ is a dimensionless scale factor
\item $T_{\text{min}}$ is the minimum tile size
\item $D$ is the maximum divisor
\item $o$ is the overlap fraction ($0 \leq o \leq 0.5$)
\item $W, H$ are the image dimensions
\end{itemize}

\subsection{Local Tile Metrics}
For each tile $t$ and each frame $f$, we compute quality metrics based on the content:

\subsubsection{Tiles containing stars}
\begin{equation}
Q_{\text{star}} = 0.6 \cdot (-\widetilde{\text{FWHM}}) + 0.2 \cdot \tilde{R} + 0.2 \cdot \tilde{C}
\end{equation}
Where FWHM is the full width at half maximum of stars, $R$ is roundness, and $C$ is local contrast.

\subsubsection{Tiles without stars}
\begin{equation}
Q_{\text{struct}} = 0.7 \cdot \widetilde{(E/\sigma)} - 0.3 \cdot \tilde{B}
\end{equation}
Where $E$ is gradient energy, $\sigma$ is local standard deviation, and $B$ is local background level.

The local weight for each tile is:
\begin{equation}
L_{f,t} = \exp(Q_{\text{local}})
\end{equation}
where $Q_{\text{local}}$ is clamped to $[-3, +3]$.

\subsection{Tile Reconstruction}
The effective weight for each tile in each frame combines global and local quality:
\begin{equation}
W_{f,t} = G_f \cdot L_{f,t}
\end{equation}

For each pixel $p$ in tile $t$:
\begin{equation}
I_t(p) = \frac{\sum_f W_{f,t} I_f(p)}{\sum_f W_{f,t}}
\end{equation}

For numerical stability, if $\sum_f W_{f,t} < \varepsilon$ (where $\varepsilon$ is a small constant), we fall back to an unweighted mean over all frames.

\subsection{Overlap-add with Window Function}
Reconstructed tiles are combined using overlap-add with a Hanning window function:
\begin{equation}
w(x,y) = \text{hann}(x) \cdot \text{hann}(y)
\end{equation}
where $\text{hann}(t) = 0.5 \cdot (1 - \cos(2\pi t))$.

Before overlap-add, each tile is normalized:
\begin{align}
T'_t &= T_t - \text{median}(T_t) \\
T''_t &= \frac{T'_t}{\text{median}(|T'_t|)} \quad \text{(if median} > \varepsilon\text{)}
\end{align}

\subsection{State-based Clustering}
For datasets with sufficient frames ($\geq 200$), we perform state-based clustering to identify physically coherent observing states. For each frame $f$, we define a state vector:
\begin{equation}
v_f = (G_f, \langle Q_{\text{tile}} \rangle, \text{Var}(Q_{\text{tile}}), B_f, \sigma_f)
\end{equation}

The number of clusters is determined dynamically:
\begin{equation}
K = \text{clip}\left(\lfloor N / 10 \rfloor, K_{\text{min}}, K_{\text{max}}\right)
\end{equation}
where $K_{\text{min}} = 5$, $K_{\text{max}} = 30$, and $N$ is the number of frames.

\subsection{Synthetic Frames and Final Stacking}
For each cluster $k$ and channel $c$, we create a synthetic frame:
\begin{equation}
S_{k,c} = \frac{\sum_{f\in\text{Cluster}_k} G_{f,c} \cdot I_{f,c}}{\sum_{f\in\text{Cluster}_k} G_{f,c}}
\end{equation}

The final result is an unweighted stack of these synthetic frames:
\begin{equation}
R_c = \frac{1}{K} \cdot \sum_k S_{k,c}
\end{equation}

\section{Validation}

\subsection{Success Criteria}
A successful reconstruction should demonstrate:
\begin{itemize}
\item Median FWHM improvement $\geq 5$--$10\%$
\item Improved field homogeneity
\item Background RMS $\leq$ classical stacking
\item No systematic tile artifacts
\end{itemize}

\subsection{Validation Metrics}
We require several validation plots to verify reconstruction quality:
\begin{itemize}
\item FWHM distribution (before/after)
\item FWHM field map (2D)
\item Global background vs time
\item Global and local weights over time
\item Tile weight distribution
\item Difference image (reconstruction - classical stacking)
\item SNR vs resolution
\end{itemize}

\section{Reduced Mode for Limited Data}
For datasets with 50-199 frames, a reduced mode is employed:
\begin{itemize}
\item Steps 1-7 are executed normally (including tile-based reconstruction)
\item State-based clustering (steps 8-9) is skipped
\item The final result is the reconstructed image from step 7
\end{itemize}

\section{Computational Complexity}

\subsection{Algorithmic Complexity}
With $F$ frames, $T$ tiles, and $P$ pixels per tile:
\begin{itemize}
\item Global metrics: $O(F \cdot N_{\text{pixels}})$
\item Tile analysis: $O(F \cdot T \cdot P)$
\item Reconstruction: $O(T \cdot F \cdot P)$
\end{itemize}

\subsection{Parallelization}
The method is highly parallelizable at the tile level (embarrassingly parallel) and optionally at the frame-within-tile level. For large-scale processing, a message queue system like RabbitMQ can enable horizontal scaling across multiple workers.

\section{Conclusion}
The tile-based quality reconstruction method provides a principled approach to astronomical image stacking that respects the spatio-temporal nature of image quality. By allowing each region of each frame to contribute according to its information content, we obtain results that surpass traditional stacking methods in both resolution and signal-to-noise ratio.

The method is particularly effective for large datasets but includes graceful degradation for smaller collections. The two equivalent preprocessing paths (Siril-based and CFA-based) offer flexibility for different workflows while maintaining methodological consistency.

Future work may explore adapting this methodology to planetary imaging, where atmospheric seeing causes even more pronounced local quality variations, and to extend the technique to spectroscopy.

\section{Acknowledgments}
We thank the open-source astronomy community, particularly the Siril development team, for their contributions to astronomical image processing.

\end{document}